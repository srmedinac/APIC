{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Third-party library imports for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "import umap\n",
    "\n",
    "# Machine Learning and statistical testing libraries\n",
    "from scipy.stats import mannwhitneyu, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "# Survival analysis libraries\n",
    "import sksurv\n",
    "from sksurv.compare import compare_survival\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored, concordance_index_ipcw, integrated_brier_score\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# Feature selection libraries\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Lifelines for additional survival analysis\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage = 0.5\n",
    "scaler_type = \"minmax\"\n",
    "feature_Sel_type = \"ElasticNet\"\n",
    "cohort = \"RTOG_0521_OS_349_feats_final\"\n",
    "l1_ratio = 0.7\n",
    "max_days = 5\n",
    "risk_treshold_method = \"median\"\n",
    "num_features = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_features_df = pd.read_csv(f'/path/to/features_with_event_time.csv', index_col=0)\n",
    "rtog_features_df = rtog_features_df.rename(columns={\"survival\": \"event\", \"survival_years\": \"time\", \"cn_deidentified\": \"patient_id\"}) #rename columns to match script\n",
    "rtog_features_df = rtog_features_df.drop(columns=[\"disease_free_survival\", \"disease_free_survival_years\", \"biochemical_failure\", \"biochemical_failure_years\", \"any_distant_mets\", \"any_distant_mets_years\", \"local_failure\", \"local_failure_years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "rtog_features = rtog_features_df.drop(['patient_id', 'RX', 'time', 'event'], axis=1)\n",
    "rtog_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "num_df = rtog_features.values\n",
    "names = rtog_features.columns.values\n",
    "\n",
    "rtog_features = pd.DataFrame(imputer.fit_transform(num_df), columns=names)\n",
    "\n",
    "rtog_features['patient_id'] = rtog_features_df['patient_id']\n",
    "rtog_features['RX'] = rtog_features_df['RX']\n",
    "rtog_features['time'] = rtog_features_df['time']\n",
    "rtog_features['event'] = rtog_features_df['event']\n",
    "rtog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_features['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_features['event'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis on leg of RT + ADT only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_1 = rtog_features.loc[rtog_features['RX'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_1['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold=0.95):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = pd.DataFrame(np.corrcoef(df.values, rowvar=False), columns=df.columns).abs() \n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    # len(to_drop)\n",
    "\n",
    "    # Drop features \n",
    "    corr_removed_df = df.drop(to_drop, axis=1)\n",
    "    \n",
    "    return corr_removed_df\n",
    "\n",
    "def boruta_selected_features(feature_df, y):\n",
    "    # define Boruta feature selection method\n",
    "    # ipdb.set_trace()\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "    feat_selector = BorutaPy(rf, n_estimators='auto', perc=95, alpha=0.05, two_step=False,verbose=0, random_state=42)\n",
    "\n",
    "    feat_selector.fit(feature_df.values, y)\n",
    "\n",
    "    # check selected features\n",
    "    boruta_selected_features = feature_df.columns[feat_selector.support_  | feat_selector.support_weak_].to_list()\n",
    "    boruta_selected_features_df = feature_df[boruta_selected_features]\n",
    "    \n",
    "    return boruta_selected_features_df\n",
    "\n",
    "def get_discriminative_features(view_features):\n",
    "\n",
    "    view_features_trim1 = view_features.drop(['patient_id', 'event', 'time'], axis=1) #'view', , 'img_id'\n",
    "    y = view_features['event']\n",
    "    if scaler_type == \"minmax\":\n",
    "        scaler = MinMaxScaler() #StandardScaler() #RobustScaler() #\n",
    "    else:\n",
    "        scaler = RobustScaler(unit_variance=True)\n",
    "    view_features_scaled = pd.DataFrame(scaler.fit_transform(view_features_trim1.values), columns=view_features_trim1.columns)\n",
    "\n",
    "    view_features_trim2 = remove_correlated_features(view_features_scaled, threshold=0.85)\n",
    "\n",
    "\n",
    "    # drop columns with zero variance using sklearn's VarianceThreshold\n",
    "    sel = VarianceThreshold(threshold=0.01)\n",
    "    sel.fit(view_features_trim2)\n",
    "    view_features_trimmed = view_features_trim2[view_features_trim2.columns[sel.get_support(indices=True)]]\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "    feat_selector = BorutaPy(rf, n_estimators='auto', perc=98, alpha=0.05, two_step=False,verbose=0, random_state=42)\n",
    "\n",
    "    feat_selector.fit(view_features_trimmed.values, y)\n",
    "\n",
    "\n",
    "    # check selected features\n",
    "    boruta_selected_features = view_features_trimmed.columns[feat_selector.support_].to_list() # | feat_selector.support_weak_\n",
    "\n",
    "    disc_features = view_features_trimmed[boruta_selected_features]\n",
    "    disc_features = pd.DataFrame(scaler.fit_transform(disc_features.values), columns=disc_features.columns)\n",
    "\n",
    "    return disc_features#, sig_pvals\n",
    "\n",
    "def plot_raincloudplots(df, stable_features, events_df, save_path):\n",
    "    rc_plot_df = df.copy()\n",
    "    rc_plot_df['event'] = events_df\n",
    "    for feature in stable_features:\n",
    "        fig = plt.figure(figsize=(5,4))\n",
    "        # Perform wilcoxon test to check if the feature is significantly different between the two groups\n",
    "        \n",
    "        stat, pvalue = f_oneway(rc_plot_df[events_df==1][feature].values, rc_plot_df[events_df==0][feature].values)\n",
    "        \n",
    "        pt.RainCloud(x='event', y=feature, data=rc_plot_df)\n",
    "        plt.title('p_val: '+str(pvalue))\n",
    "        plt.show()\n",
    "        fig.savefig(save_path+'_'+feature+'.png', dpi=300, bbox_inches='tight')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hr_and_pval(threshold, val_risk_scores, y_val_survlabel):\n",
    "\n",
    "    # Calculate Kaplan-Meier estimator for different risk groups\n",
    "    risk_groups = threshold #np.mean(val_risk_scores)#np.percentile(test_risk_scores, 50)\n",
    "    risk_group_labels = np.array([1 if x > risk_groups else 0 for x in val_risk_scores])#np.digitize(test_risk_scores, risk_groups)\n",
    "    survival_probs = []\n",
    "    survival_times = []\n",
    "\n",
    "    for group_label in np.unique(risk_group_labels):\n",
    "        group_indices = np.where(risk_group_labels == group_label)\n",
    "        group_time, group_survival_prob = kaplan_meier_estimator(events[group_indices], times[group_indices])\n",
    "        survival_probs.append(group_survival_prob)\n",
    "        survival_times.append(group_time)\n",
    "\n",
    "\n",
    "    tstat, pval, stats0, stats1 = compare_survival(y_val_survlabel, risk_group_labels, return_stats=True)\n",
    "\n",
    "    return tstat, pval\n",
    "\n",
    "\n",
    "# divide the centerview data on training and test set\n",
    "\n",
    "training_data, holdout_data = train_test_split(rtog_leg_1, test_size=split_percentage, random_state=42, stratify=rtog_leg_1['event'])\n",
    "\n",
    "N_runs = 50\n",
    "# Set the seed\n",
    "random.seed(42)\n",
    "\n",
    "# Generate 50 random numbers\n",
    "random_numbers = [random.randint(0, 1000) for _ in range(N_runs)]\n",
    "\n",
    "bootstrap_metrics = pd.DataFrame()\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "\n",
    "print(\"Running {} iterations\".format(N_runs))\n",
    "\n",
    "for i in range(N_runs):\n",
    "\n",
    "    random_seed = random_numbers[i] #np.random.randint(1, 1000)\n",
    "\n",
    "    # divide the training data on training and validation set\n",
    "    train_data, val_data = train_test_split(training_data, test_size=split_percentage, random_state=random_seed, stratify=training_data['event'])\n",
    "\n",
    "    X_train = train_data.drop(['patient_id','event', 'time'], axis=1).reset_index(drop=True)\n",
    "    y_train = train_data[['patient_id','event', 'time']].reset_index(drop=True)\n",
    "\n",
    "    X_val = val_data.drop(['patient_id','event', 'time'], axis=1).reset_index(drop=True)\n",
    "    y_val = val_data[['patient_id','event', 'time']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    #scaler = RobustScaler(unit_variance=True)#MinMaxScaler()\n",
    "    if scaler_type == \"minmax\":\n",
    "        scaler = MinMaxScaler() #StandardScaler() #RobustScaler() #\n",
    "    else:\n",
    "        scaler = RobustScaler(unit_variance=True)\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "\n",
    "    varTh = VarianceThreshold(threshold=0.05)\n",
    "    varTh.fit(X_train)\n",
    "    X_train = X_train[X_train.columns[varTh.get_support(indices=True)]]\n",
    "    X_val = X_val[X_val.columns[varTh.get_support(indices=True)]]\n",
    "\n",
    "    X_train_decorrelated = remove_correlated_features(X_train, 0.95)\n",
    "    X_train_trimmed = X_train_decorrelated.copy()\n",
    "    # apply boruta feature selection on the training set\n",
    "    #X_train_trimmed = boruta_selected_features(X_train_decorrelated, y_train['event'].values)\n",
    "    \n",
    "    X_val_trimmed = X_val[X_train_trimmed.columns]\n",
    "\n",
    "    print(f\"Training features input to ElasticNet model (l1={l1_ratio}) = {X_train_trimmed.shape}\")\n",
    "\n",
    "    y_train_survlabel = Surv.from_dataframe('event', 'time', y_train)\n",
    "    y_val_survlabel = Surv.from_dataframe('event', 'time', y_val)\n",
    "\n",
    "    try:\n",
    "        coxnet_pipe = make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alpha_min_ratio=0.01, max_iter=20, fit_baseline_model=True))\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "        coxnet_pipe.fit(X_train_trimmed, y_train_survlabel)\n",
    "\n",
    "        estimated_alphas = coxnet_pipe.named_steps[\"coxnetsurvivalanalysis\"].alphas_\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "        gcv = GridSearchCV(\n",
    "        make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, fit_baseline_model=True)),\n",
    "        param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in estimated_alphas]},\n",
    "        cv=cv,\n",
    "        error_score=0.5,\n",
    "        n_jobs=1,\n",
    "        ).fit(X_train_trimmed, y_train_survlabel)\n",
    "\n",
    "        cv_results = pd.DataFrame(gcv.cv_results_)\n",
    "\n",
    "        alphas = cv_results.param_coxnetsurvivalanalysis__alphas.map(lambda x: x[0])\n",
    "        mean = cv_results.mean_test_score\n",
    "        std = cv_results.std_test_score\n",
    "\n",
    "\n",
    "        best_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "        best_coefs = pd.DataFrame(best_model.coef_, index=X_train_trimmed.columns, columns=[\"coefficient\"])\n",
    "\n",
    "        non_zero = np.sum(best_coefs.iloc[:, 0] != 0)\n",
    "        non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "        coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "        print(\"Number of non-zero features: {}\".format(non_zero))\n",
    "\n",
    "        coxnet_pred = gcv.best_estimator_\n",
    "        C_test = coxnet_pred.score(X_val_trimmed, y_val_survlabel)\n",
    "        print('C-index on test set: {:.3f}'.format(C_test))\n",
    "\n",
    "        val_risk_scores = coxnet_pred.predict(X_val_trimmed)\n",
    "        events, times = y_val['event'].values.astype(bool), y_val['time'].values\n",
    "\n",
    "        coxnet_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "\n",
    "        hr_median, pval_median = get_hr_and_pval(np.median(val_risk_scores), val_risk_scores, y_val_survlabel)\n",
    "        hr_mean, pval_mean = get_hr_and_pval(np.mean(val_risk_scores), val_risk_scores, y_val_survlabel)\n",
    "\n",
    "\n",
    "        temp_dict = {'Seed': [random_seed], 'Test_Cindex': [C_test], 'Test_pval_mean': [pval_mean], 'Hazard_ratio_mean': [hr_mean], 'Test_pval_median': [pval_median], 'Hazard_ratio_median': [hr_median], 'Nonzero_features_count': [non_zero]}\n",
    "        temp_df = pd.DataFrame.from_dict(temp_dict, orient='columns')\n",
    "        temp_df['Nonzero_features']= [coef_order.values.tolist()]\n",
    "        temp_df['Nonzero_features_coefs']= [non_zero_coefs['coefficient'].values.tolist()]\n",
    "\n",
    "\n",
    "        bootstrap_metrics = pd.concat([bootstrap_metrics, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "        if (i+1)%5 == 0:\n",
    "            print(\"Iteration {} completed\".format(i+1))\n",
    "    except:\n",
    "        print(\"Iteration {} failed\".format(i+1))\n",
    "        print(\"Retrying iteration {}...\".format(i+1))\n",
    "        i=i-1\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frequency_dict = {}\n",
    "feature_coefficient_strength_dict = {}\n",
    "for feature_list in bootstrap_metrics['Nonzero_features']:\n",
    "    list_idx = bootstrap_metrics['Nonzero_features'].values.tolist().index(feature_list)\n",
    "    for feature in feature_list:\n",
    "        idx = feature_list.index(feature)\n",
    "        feat_coef = np.abs(bootstrap_metrics['Nonzero_features_coefs'][list_idx][idx])\n",
    "        \n",
    "        if feature in feature_frequency_dict:\n",
    "            feature_frequency_dict[feature] += 1\n",
    "        else:\n",
    "            feature_frequency_dict[feature] = 1\n",
    "        \n",
    "        if feature in feature_coefficient_strength_dict:\n",
    "            feature_coefficient_strength_dict[feature] += feat_coef\n",
    "        else:\n",
    "            feature_coefficient_strength_dict[feature] = feat_coef\n",
    "\n",
    "print(feature_frequency_dict)\n",
    "print(feature_coefficient_strength_dict)\n",
    "\n",
    "feature_frequency = pd.DataFrame(feature_frequency_dict.items(), columns=['feature', 'count'])\n",
    "feature_coefs = pd.DataFrame(feature_coefficient_strength_dict.items(), columns=['feature', 'coefficient'])\n",
    "\n",
    "# merge the two dataframes\n",
    "feature_frequency = feature_frequency.merge(feature_coefs, on='feature', how='left')\n",
    "\n",
    "feature_frequency = feature_frequency.sort_values(by='coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# get feature score using the formula: feature_score = feature_count * feature_coefficient_strength/50 and save it in a new column\n",
    "\n",
    "feature_frequency['feature_score'] = feature_frequency['count'] * feature_frequency['coefficient']/N_runs\n",
    "\n",
    "feature_frequency = feature_frequency.sort_values(by='feature_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "feature_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = training_data[feature_frequency['feature'][:num_features].values]\n",
    "holdout_df = holdout_data[feature_frequency['feature'][:num_features].values]\n",
    "\n",
    "\n",
    "X_training = train_df.reset_index(drop=True)\n",
    "y_training = training_data[['patient_id','event', 'time']].reset_index(drop=True)\n",
    "\n",
    "X_holdout = holdout_df.reset_index(drop=True)\n",
    "y_holdout = holdout_data[['patient_id','event', 'time']].reset_index(drop=True)\n",
    "\n",
    "if scaler_type == \"minmax\":\n",
    "    second_scaler = MinMaxScaler() #StandardScaler() #RobustScaler() #\n",
    "else:\n",
    "    second_scaler = RobustScaler(unit_variance=True)\n",
    "X_training = pd.DataFrame(second_scaler.fit_transform(X_training), columns=X_training.columns)\n",
    "X_holdout = pd.DataFrame(second_scaler.transform(X_holdout), columns=X_holdout.columns)\n",
    "\n",
    "varTh = VarianceThreshold(threshold=0.01)\n",
    "varTh.fit(X_training)\n",
    "X_training = X_training[X_training.columns[varTh.get_support(indices=True)]]\n",
    "X_holdout = X_holdout[X_holdout.columns[varTh.get_support(indices=True)]]\n",
    "\n",
    "X_training_trimmed = remove_correlated_features(X_training, 0.8)\n",
    "X_holdout_trimmed = X_holdout[X_training_trimmed.columns]\n",
    "# concat the training and holdout data\n",
    "\n",
    "print(\"Training data: {}\".format(X_training_trimmed.shape))\n",
    "print(\"Testing data: {}\".format(X_holdout_trimmed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training_survlabel = Surv.from_dataframe('event', 'time', y_training)\n",
    "y_holdout_survlabel = Surv.from_dataframe('event', 'time', y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_training_survlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10.0 ** np.linspace(-4, 4, 50)\n",
    "coefficients = {}\n",
    "\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "for alpha in alphas:\n",
    "    cph.set_params(alpha=alpha)\n",
    "    cph.fit(X_training_trimmed, y_training_survlabel)\n",
    "    key = round(alpha, 5)\n",
    "    coefficients[key] = cph.coef_\n",
    "\n",
    "coefficients = pd.DataFrame.from_dict(coefficients).rename_axis(index=\"feature\", columns=\"alpha\").set_index(X_training_trimmed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(coefs, n_highlight):\n",
    "    _, ax = plt.subplots(figsize=(9, 6))\n",
    "    n_features = coefs.shape[0]\n",
    "    alphas = coefs.columns\n",
    "    for row in coefs.itertuples():\n",
    "        ax.semilogx(alphas, row[1:], \".-\", label=row.Index)\n",
    "\n",
    "    alpha_min = alphas.min()\n",
    "    top_coefs = coefs.loc[:, alpha_min].map(abs).sort_values().tail(n_highlight)\n",
    "    for name in top_coefs.index:\n",
    "        coef = coefs.loc[name, alpha_min]\n",
    "        plt.text(alpha_min, coef, name + \"   \", horizontalalignment=\"right\", verticalalignment=\"center\")\n",
    "\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"alpha\")\n",
    "    ax.set_ylabel(\"coefficient\")\n",
    "\n",
    "plot_coefficients(coefficients, n_highlight=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coxnet_pipe = make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alpha_min_ratio=0.01, max_iter=50, fit_baseline_model=True))\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "coxnet_pipe.fit(X_training_trimmed, y_training_survlabel)\n",
    "\n",
    "estimated_alphas = coxnet_pipe.named_steps[\"coxnetsurvivalanalysis\"].alphas_\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gcv = GridSearchCV(\n",
    "    make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, fit_baseline_model=True)),\n",
    "    param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in estimated_alphas]},\n",
    "    cv=cv,\n",
    "    error_score=0.5,\n",
    "    n_jobs=1,\n",
    ").fit(X_training_trimmed, y_training_survlabel)\n",
    "\n",
    "cv_results = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = cv_results.param_coxnetsurvivalanalysis__alphas.map(lambda x: x[0])\n",
    "mean = cv_results.mean_test_score\n",
    "std = cv_results.std_test_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(alphas, mean)\n",
    "ax.fill_between(alphas, mean - std, mean + std, alpha=0.15)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"concordance index\", fontsize=16)\n",
    "ax.set_xlabel(\"alpha\", fontsize=16)\n",
    "yticks = [np.round(x,2) for x in ax.get_yticks()]\n",
    "ax.set_yticklabels(yticks, fontsize=14)\n",
    "ax.axvline(gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0], c=\"C1\")\n",
    "ax.axhline(0.5, color=\"grey\", linestyle=\"--\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "best_coefs = pd.DataFrame(best_model.coef_, index=X_training_trimmed.columns, columns=[\"coefficient\"])\n",
    "\n",
    "non_zero = np.sum(best_coefs.iloc[:, 0] != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero}\")\n",
    "\n",
    "non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "\n",
    "fig1, ax = plt.subplots(figsize=(8,10))\n",
    "non_zero_coefs.loc[coef_order].plot.barh(ax=ax, legend=False)\n",
    "ax.set_xlabel(\"Feature Coefficient\", fontsize=20)\n",
    "ax.xaxis.set_tick_params(labelsize=16)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coefs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coefs.to_dict()['coefficient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Metrics for model\")\n",
    "coxnet_pred = gcv.best_estimator_\n",
    "\n",
    "training_prediction = coxnet_pred.predict(X_training_trimmed)\n",
    "holdout_prediction = coxnet_pred.predict(X_holdout_trimmed)\n",
    "\n",
    "training_survival = coxnet_pred.predict_survival_function(X_training_trimmed)\n",
    "times_training = np.arange(int(np.min(y_training_survlabel['time'])), int(np.max(y_training_survlabel[\"time\"])))\n",
    "try:\n",
    "    survival_prediction_training = np.asarray([[fn(t) for t in times_training] for fn in training_survival])\n",
    "except:\n",
    "    print(\"Error in calculating survival prediction for training set\")\n",
    "\n",
    "holdout_survival = coxnet_pred.predict_survival_function(X_holdout_trimmed)\n",
    "times_holdout = np.arange(int(np.min(y_holdout_survlabel['time'])), int(np.max(y_holdout_survlabel[\"time\"])))\n",
    "try:\n",
    "    survival_prediction_holdout = np.asarray([[fn(t) for t in times_holdout] for fn in holdout_survival])\n",
    "except:\n",
    "    print(\"Error in calculating survival prediction for holdout set\")\n",
    "\n",
    "c_index_training = concordance_index_censored(y_training_survlabel[\"event\"], y_training_survlabel[\"time\"], training_prediction)\n",
    "c_index_holdout = concordance_index_censored(y_holdout_survlabel[\"event\"], y_holdout_survlabel[\"time\"], holdout_prediction)\n",
    "print('C-index on Training set: {:.3f}'.format(c_index_training[0]))\n",
    "print('C-index on Holdout set: {:.3f}'.format(c_index_holdout[0]))\n",
    "\n",
    "# calculate the IPCW C-index for the training and holdout set\n",
    "c_ipcw_training = concordance_index_ipcw(y_training_survlabel, y_training_survlabel, training_prediction)\n",
    "c_ipcw_holdout = concordance_index_ipcw(y_training_survlabel, y_holdout_survlabel, holdout_prediction)\n",
    "print('IPCW C-index on Training set: {:.3f}'.format(c_ipcw_training[0]))\n",
    "print('IPCW C-index on Holdout set: {:.3f}'.format(c_ipcw_holdout[0]))\n",
    "\n",
    "try:\n",
    "    ibs_training = integrated_brier_score(y_training_survlabel, y_training_survlabel, survival_prediction_training, times_training)\n",
    "    ibs_holdout = integrated_brier_score(y_training_survlabel, y_holdout_survlabel, survival_prediction_holdout, times_holdout)\n",
    "    print('IBS on training set: {:.3f}'.format(ibs_training))\n",
    "    print('IBS on Holdout set: {:.3f}'.format(ibs_holdout))\n",
    "except:\n",
    "    print(\"Error in calculating IBS\")\n",
    "\n",
    "# create a dataframe to store the model type and c-index\n",
    "model_metrics = pd.DataFrame()\n",
    "model_metrics['cohort'] = [\"Disparity\"]\n",
    "model_metrics['c_index_train'] = [c_index_training[0]]\n",
    "model_metrics['c_index_holdout'] = [c_index_holdout[0]]\n",
    "model_metrics['c_index_ipcw_train'] = [c_ipcw_training[0]]\n",
    "model_metrics['c_index_ipcw_holdout'] = [c_ipcw_holdout[0]]\n",
    "try:\n",
    "    model_metrics['integrated_brier_score_train'] = [ibs_training]\n",
    "    model_metrics['integrated_brier_score_holdout'] = [ibs_holdout]\n",
    "except:\n",
    "    model_metrics['integrated_brier_score_train'] = [0]\n",
    "    model_metrics['integrated_brier_score_holdout'] = [0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_risk_scores = coxnet_pred.predict(X_training_trimmed)\n",
    "events, times = y_training['event'].values.astype(bool),   y_training['time'].values\n",
    "coxnet_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(training_risk_scores), max(training_risk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(training_risk_scores)\n",
    "std = np.std(training_risk_scores)\n",
    "\n",
    "# Calculate the range\n",
    "lower_bound = mean - std\n",
    "upper_bound = mean + std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_risk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = np.linspace(lower_bound, upper_bound, num=int((upper_bound - (lower_bound)) / 0.001) + 1)\n",
    "p_values = []\n",
    "thresholds = []\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    # Assuming 'train_risk_group_labels' needs to be defined based on the current threshold\n",
    "    train_risk_group_labels = np.array([1 if x > threshold else 0 for x in training_risk_scores])#np.digitize(train_risk_scores, risk_groups)\n",
    "    #p_values.append(multivariate_logrank_test(times, train_risk_group_labels, events).p_value)\n",
    "    thresholds.append(threshold)\n",
    "    p_values.append(logrank_test(times[train_risk_group_labels==0], times[train_risk_group_labels==1], events[train_risk_group_labels==0], events[train_risk_group_labels==1]).p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_threshold = np.median(training_risk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot p values vs thresholds\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(thresholds, p_values)\n",
    "ax.set_xlabel(\"Threshold value\")\n",
    "ax.set_ylabel(\"P-value\")\n",
    "ax.set_title(\"P-value vs Threshold\")\n",
    "#plot a red line in the minimum p-value\n",
    "min_pval_idx = np.argmin(p_values)\n",
    "ax.axvline(risk_threshold, color='blue', linestyle='--')\n",
    "ax.axvline(thresholds[min_pval_idx], color='r', linestyle='--')\n",
    "ax.axvline(np.median(training_risk_scores), color='g', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_risk_group_labels = np.array([1 if x > risk_threshold else 0 for x in training_risk_scores])#np.digitize(train_risk_scores, risk_groups)\n",
    "train_survival_probs = []\n",
    "train_survival_times = []\n",
    "\n",
    "for group_label in np.unique(train_risk_group_labels):\n",
    "    group_indices = np.where(train_risk_group_labels == group_label)\n",
    "    group_time, group_survival_prob = kaplan_meier_estimator(events[group_indices], times[group_indices])\n",
    "    train_survival_probs.append(group_survival_prob)\n",
    "    train_survival_times.append(group_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holdout_risk_scores = coxnet_pred.predict(X_holdout_trimmed)\n",
    "events, times = y_holdout['event'].values.astype(bool),   y_holdout['time'].values\n",
    "\n",
    "coxnet_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "\n",
    "\n",
    "holdout_risk_group_labels = np.array([1 if x > risk_threshold else 0 for x in holdout_risk_scores])#np.digitize(test_risk_scores, risk_groups)\n",
    "holdout_survival_probs = []\n",
    "holdout_survival_times = []\n",
    "\n",
    "for group_label in np.unique(holdout_risk_group_labels):\n",
    "    group_indices = np.where(holdout_risk_group_labels == group_label)\n",
    "    group_time, group_survival_prob = kaplan_meier_estimator(events[group_indices], times[group_indices])\n",
    "    holdout_survival_probs.append(group_survival_prob)\n",
    "    holdout_survival_times.append(group_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = logrank_test(times[holdout_risk_group_labels==0], times[holdout_risk_group_labels==1], events[holdout_risk_group_labels==0], events[holdout_risk_group_labels==1])\n",
    "results.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = multivariate_logrank_test(times, holdout_risk_group_labels, events)\n",
    "results.p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_holdout['risk_score'] = holdout_risk_scores\n",
    "y_holdout['risk_group'] = holdout_risk_group_labels\n",
    "y_holdout['patient_id'] = y_holdout['patient_id']\n",
    "y_holdout = y_holdout.sort_values(by=['patient_id']).reset_index(drop=True)\n",
    "y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training['risk_score'] = training_risk_scores\n",
    "y_training['risk_group'] = train_risk_group_labels\n",
    "y_training['patient_id'] = y_training['patient_id']\n",
    "y_training = y_training.sort_values(by=['patient_id']).reset_index(drop=True)\n",
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "\n",
    "LL_train = y_training.drop(['patient_id', 'risk_score'], axis=1)\n",
    "LL_holdout = y_holdout.drop(['patient_id', 'risk_score'], axis=1)\n",
    "cph_train = CoxPHFitter()\n",
    "cph_train.fit(LL_train, duration_col='time', event_col='event', show_progress=False)\n",
    "\n",
    "cph_holdout = CoxPHFitter()\n",
    "cph_holdout.fit(LL_holdout, duration_col='time', event_col='event', show_progress=False)\n",
    "\n",
    "\n",
    "training_results = cph_train.summary\n",
    "training_p = multivariate_logrank_test(y_training['time'], y_training['risk_group'], y_training['event']).p_value# training_results['p'].values[0]\n",
    "training_hr = training_results['exp(coef)'].values[0]\n",
    "training_ci_lower = training_results['exp(coef) lower 95%'].values[0]\n",
    "training_ci_upper = training_results['exp(coef) upper 95%'].values[0]\n",
    "training_log_likelihood = cph_train.log_likelihood_\n",
    "model_metrics['training_p_value'] = [training_p]\n",
    "model_metrics['training_hazard_ratio'] = [training_hr]\n",
    "model_metrics['training_hr_ci_lower'] = [training_ci_lower]\n",
    "model_metrics['training_hr_ci_upper'] = [training_ci_upper]\n",
    "model_metrics['training_log_likelihood'] = [training_log_likelihood]\n",
    "model_metrics['training_parameters'] = [cph_train.params_.shape[0]]\n",
    "\n",
    "training_data_stats = (training_p, training_hr, training_ci_lower, training_ci_upper)\n",
    "\n",
    "\n",
    "holdout_results = cph_holdout.summary\n",
    "holdout_p = multivariate_logrank_test(y_holdout['time'], y_holdout['risk_group'], y_holdout['event']).p_value # holdout_results['p'].values[0]\n",
    "holdout_hr = holdout_results['exp(coef)'].values[0]\n",
    "holdout_ci_lower = holdout_results['exp(coef) lower 95%'].values[0]\n",
    "holdout_ci_upper = holdout_results['exp(coef) upper 95%'].values[0]\n",
    "holdout_log_likelihood = cph_holdout.log_likelihood_\n",
    "model_metrics['holdout_p_value'] = [holdout_p]\n",
    "model_metrics['holdout_hazard_ratio'] = [holdout_hr]\n",
    "model_metrics['holdout_hr_ci_lower'] = [holdout_ci_lower]\n",
    "model_metrics['holdout_hr_ci_upper'] = [holdout_ci_upper]\n",
    "model_metrics['holdout_log_likelihood'] = [holdout_log_likelihood]\n",
    "model_metrics['holdout_parameters'] = [cph_holdout.params_.shape[0]]\n",
    "\n",
    "holdout_data_stats = (holdout_p, holdout_hr, holdout_ci_lower, holdout_ci_upper)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout.score(LL_holdout, scoring_method='log_likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_train.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_km_curve_lifelines(data_df, data_stats, figure_save_path, title_str):\n",
    "    \n",
    "    # Create a colormap\n",
    "    cmap = plt.cm.get_cmap('Reds')\n",
    "    # Choose a shade of red\n",
    "    hr_shade = cmap(0.75)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('Blues')\n",
    "    # Choose a shade of red\n",
    "    lr_shade = cmap(0.75)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "\n",
    "    data_high_risk = data_df[data_df['risk_group']==1]\n",
    "    data_low_risk = data_df[data_df['risk_group']==0]\n",
    "\n",
    "    kmf_hr = KaplanMeierFitter()\n",
    "    kmf_hr.fit(data_high_risk['time'], event_observed=data_high_risk['event'], label='High Risk')\n",
    "    kmf_hr.plot_survival_function(ax=ax, color='#f8766d', lw=2, show_censors=True)\n",
    "\n",
    "    kmf_lr = KaplanMeierFitter()\n",
    "    kmf_lr.fit(data_low_risk['time'], event_observed=data_low_risk['event'], label='Low Risk')\n",
    "    kmf_lr.plot_survival_function(ax=ax, color='#03bfc4', lw=2, show_censors=True, )\n",
    "    \n",
    "    \n",
    "    print(\"Low risk median survival time: \",kmf_lr.median_survival_time_)\n",
    "    print(\"High risk median survival time: \",kmf_hr.median_survival_time_)\n",
    "    max_median_survival_time = max(kmf_hr.median_survival_time_ , kmf_lr.median_survival_time_)\n",
    "    if max_median_survival_time == np.inf:\n",
    "        plt.axhline(y=0.5, color='black', linestyle='--', lw=1)\n",
    "    else:\n",
    "        plt.plot([0, max_median_survival_time], [0.5, 0.5], color='black', linestyle='--', lw=1)\n",
    "    # Vertical lines up to y=0.5, using plot for precise control\n",
    "    plt.plot([kmf_hr.median_survival_time_, kmf_hr.median_survival_time_], [0, 0.5], color='black', linestyle='--', lw=1)\n",
    "    plt.plot([kmf_lr.median_survival_time_, kmf_lr.median_survival_time_], [0, 0.5], color='black', linestyle='--', lw=1)\n",
    "    ax.set_title(title_str, fontsize=26)\n",
    "\n",
    "    yticks = [np.round(x,1) for x in ax.get_yticks()]\n",
    "    ax.set_yticklabels(yticks, fontsize=20)\n",
    "    ax.set_xticklabels(ax.get_xticks().astype(int), fontsize=20)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (Years)', fontsize=28)\n",
    "    ax.set_ylabel('Overall Survival Probability', fontsize=28)\n",
    "    data_p, data_hr, data_ci_lower, data_ci_upper = data_stats\n",
    "    format_p = lambda p: f\"{p:.1e}\" if p < 0.001 else f\"{p:.4f}\"\n",
    "\n",
    "# Updated string formatting\n",
    "    data_stats_text = f'p: {format_p(data_p)}\\nHR: {data_hr:.2f} [95% CI: {data_ci_lower:.2f} - {data_ci_upper:.2f}]'\n",
    "    #data_stats_text = f'p: {data_p:.1e if data_p < 0.001 else data_p:.4f}\\nHR: {data_hr:.2f} [95% CI: {data_ci_lower:.2f} - {data_ci_upper:.2f}]'\n",
    "    ax.text(0.03, 0.1, data_stats_text, transform=ax.transAxes, fontsize=24, verticalalignment='bottom')\n",
    "\n",
    "    # Add the risk table at the bottom of the KM plot on ax[1] (the bottom subplot)\n",
    "    sns.despine()\n",
    "    add_at_risk_counts(kmf_hr, kmf_lr, ax=ax, fontsize=20)\n",
    "    ax.legend(fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(figure_save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_str = 'Training Set - RT+ADT treated patients (N={:d})'.format(len(y_training))\n",
    "train_figure_save_path = f'KM_curve_training.png'\n",
    "plot_km_curve_lifelines(y_training, training_data_stats, train_figure_save_path, train_title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the KM curve for the holdout data\n",
    "\n",
    "holdout_title_str = 'Holdout Set - RT+ADT treated patients (N={:d})'.format(len(y_holdout))\n",
    "holdout_figure_save_path = f'KM_curve_holdout.png'\n",
    "plot_km_curve_lifelines(y_holdout, holdout_data_stats, holdout_figure_save_path, holdout_title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking selected feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(X_training_trimmed):\n",
    "    pvalue = mannwhitneyu(X_training_trimmed[feature], y_training['event']).pvalue\n",
    "    print(feature)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    pt.RainCloud(x=rtog_features['event'], y=X_training_trimmed[feature])\n",
    "    plt.title(f'p: {pvalue:.2}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on RT+ADT+CT group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_2 = rtog_features.loc[rtog_features['RX'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_2['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtog_leg_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_doce = rtog_leg_2.drop(['patient_id', 'event', 'time'], axis=1).reset_index(drop=True)\n",
    "y_holdout_doce = rtog_leg_2[['patient_id','event', 'time']].reset_index(drop=True)\n",
    "X_holdout_doce = pd.DataFrame(scaler.transform(X_holdout_doce), columns=X_holdout_doce.columns)\n",
    "X_holdout_doce_trimmed = X_holdout_doce[X_training_trimmed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_holdout_doce_survlabel = Surv.from_dataframe('event', 'time', y_holdout_doce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_doce_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_doce_risk_scores = coxnet_pred.predict(X_holdout_doce_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce_events, doce_times = y_holdout_doce['event'].values.astype(bool), y_holdout_doce['time'].values\n",
    "coxnet_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "\n",
    "holdout_doce_risk_group_labels = np.array([1 if x > risk_threshold else 0 for x in holdout_doce_risk_scores])\n",
    "holdout_doce_survival_probs = []\n",
    "holdout_doce_survival_times = []\n",
    "\n",
    "for group_label in np.unique(holdout_doce_risk_group_labels):\n",
    "    group_indices = np.where(holdout_doce_risk_group_labels == group_label)\n",
    "    group_time, group_survival_prob = kaplan_meier_estimator(doce_events[group_indices], doce_times[group_indices])\n",
    "    holdout_survival_probs.append(group_survival_prob)\n",
    "    holdout_survival_times.append(group_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logrank_test(doce_times[holdout_doce_risk_group_labels==0], doce_times[holdout_doce_risk_group_labels==1], doce_events[holdout_doce_risk_group_labels==0], doce_events[holdout_doce_risk_group_labels==1])\n",
    "results.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce_results = multivariate_logrank_test(doce_times, holdout_doce_risk_group_labels, doce_events)\n",
    "doce_results.p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_holdout_doce['risk_score'] = holdout_doce_risk_scores\n",
    "y_holdout_doce['risk_group'] = holdout_doce_risk_group_labels\n",
    "y_holdout_doce['patient_id'] = y_holdout_doce['patient_id']\n",
    "y_holdout_doce = y_holdout_doce.sort_values(by=['patient_id']).reset_index(drop=True)\n",
    "y_holdout_doce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for treatment leg cohort\")\n",
    "coxnet_pred = gcv.best_estimator_\n",
    "\n",
    "doce_holdout_prediction = coxnet_pred.predict(X_holdout_doce_trimmed)\n",
    "\n",
    "doce_holdout_survival = coxnet_pred.predict_survival_function(X_holdout_doce_trimmed)\n",
    "times_holdout_doce = np.arange(int(np.min(y_holdout_doce_survlabel['time'])), int(np.max(y_holdout_doce_survlabel[\"time\"])))\n",
    "survival_prediction_holdout_doce = np.asarray([[fn(t) for t in times_holdout_doce] for fn in doce_holdout_survival])\n",
    "\n",
    "c_index_holdout = concordance_index_censored(y_holdout_doce_survlabel[\"event\"], y_holdout_doce_survlabel[\"time\"], doce_holdout_prediction)\n",
    "print('C-index on Holdout set: {:.3f}'.format(c_index_holdout[0]))\n",
    "\n",
    "c_ipcw_holdout = concordance_index_ipcw(y_training_survlabel, y_holdout_doce_survlabel, doce_holdout_prediction)\n",
    "print('IPCW C-index on Holdout set: {:.3f}'.format(c_ipcw_holdout[0]))\n",
    "\n",
    "model_metrics_doce = pd.DataFrame()\n",
    "model_metrics_doce['cohort'] = [\"doce\"]\n",
    "model_metrics_doce['c_index_holdout'] = [c_index_holdout[0]]\n",
    "model_metrics_doce['c_index_ipcw_holdout'] = [c_ipcw_holdout[0]]\n",
    "model_metrics_doce['integrated_brier_score_holdout'] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LL_holdout_doce = y_holdout_doce.drop(['patient_id', 'risk_score'], axis=1)\n",
    "cph_holdout_doce = CoxPHFitter()\n",
    "cph_holdout_doce.fit(LL_holdout_doce, duration_col='time', event_col='event', show_progress=False)\n",
    "\n",
    "doce_holdout_results = cph_holdout_doce.summary\n",
    "doce_holdout_p = multivariate_logrank_test(y_holdout_doce['time'], y_holdout_doce['risk_group'], y_holdout_doce['event']).p_value # holdout_results['p'].values[0]\n",
    "doce_holdout_hr = doce_holdout_results['exp(coef)'].values[0]\n",
    "doce_holdout_ci_lower = doce_holdout_results['exp(coef) lower 95%'].values[0]\n",
    "doce_holdout_ci_upper = doce_holdout_results['exp(coef) upper 95%'].values[0]\n",
    "doce_holdout_log_likelihood = cph_holdout_doce.log_likelihood_\n",
    "model_metrics_doce['holdout_p_value'] = [doce_holdout_p]\n",
    "model_metrics_doce['holdout_hazard_ratio'] = [doce_holdout_hr]\n",
    "model_metrics_doce['holdout_hr_ci_lower'] = [doce_holdout_ci_lower]\n",
    "model_metrics_doce['holdout_hr_ci_upper'] = [doce_holdout_ci_upper]\n",
    "model_metrics_doce['holdout_log_likelihood'] = [doce_holdout_log_likelihood]\n",
    "model_metrics_doce['holdout_parameters'] = [cph_holdout_doce.params_.shape[0]]\n",
    "\n",
    "doce_holdout_data_stats = (doce_holdout_p, doce_holdout_hr, doce_holdout_ci_lower, doce_holdout_ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout_doce.score(LL_holdout, scoring_method='log_likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout_doce.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_holdout_doce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce_holdout_title_str = 'Test Set - RT+ADT+CT (Docetaxel) treated patients (N={:d})'.format(len(y_holdout_doce))\n",
    "doce_holdout_figure_save_path = f'KM_curve_holdout_treatment.png'\n",
    "plot_km_curve_lifelines(y_holdout_doce, doce_holdout_data_stats, doce_holdout_figure_save_path, doce_holdout_title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(X_holdout_doce_trimmed):\n",
    "    pvalue = mannwhitneyu(X_holdout_doce_trimmed[feature], y_holdout_doce['event']).pvalue\n",
    "    print(feature)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    pt.RainCloud(x=rtog_features['event'], y=X_holdout_doce_trimmed[feature])\n",
    "    plt.title(f'p: {pvalue:.2}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIC-low patients from both arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_favorable_risk = y_holdout_doce[y_holdout_doce['risk_group'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_favorable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_favorable_risk['chemo'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chemo_favorable_risk = y_holdout[y_holdout['risk_group'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chemo_favorable_risk['chemo'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chemo_favorable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dfs\n",
    "favorable_risk = pd.concat([chemo_favorable_risk, no_chemo_favorable_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_holdout_doce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_holdout_doce = favorable_risk.drop(['patient_id', 'risk_group', 'risk_score'], axis=1)\n",
    "cph_holdout_doce = CoxPHFitter()\n",
    "cph_holdout_doce.fit(LL_holdout_doce, duration_col='time', event_col='event', show_progress=False)\n",
    "\n",
    "doce_holdout_results = cph_holdout_doce.summary\n",
    "doce_holdout_p = multivariate_logrank_test(favorable_risk['time'], favorable_risk['chemo'], favorable_risk['event']).p_value # holdout_results['p'].values[0] # change group to chemo/nochemo\n",
    "doce_holdout_hr = doce_holdout_results['exp(coef)'].values[0]\n",
    "doce_holdout_ci_lower = doce_holdout_results['exp(coef) lower 95%'].values[0]\n",
    "doce_holdout_ci_upper = doce_holdout_results['exp(coef) upper 95%'].values[0]\n",
    "doce_holdout_log_likelihood = cph_holdout_doce.log_likelihood_\n",
    "model_metrics_doce['holdout_p_value'] = [doce_holdout_p]\n",
    "model_metrics_doce['holdout_hazard_ratio'] = [doce_holdout_hr]\n",
    "model_metrics_doce['holdout_hr_ci_lower'] = [doce_holdout_ci_lower]\n",
    "model_metrics_doce['holdout_hr_ci_upper'] = [doce_holdout_ci_upper]\n",
    "model_metrics_doce['holdout_log_likelihood'] = [doce_holdout_log_likelihood]\n",
    "model_metrics_doce['holdout_parameters'] = [cph_holdout_doce.params_.shape[0]]\n",
    "\n",
    "doce_holdout_data_stats = (doce_holdout_p, doce_holdout_hr, doce_holdout_ci_lower, doce_holdout_ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce_holdout_data_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout_doce.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_km_same_risk_group(data_df1, data_df2, data_stats, figure_save_path, title_str):\n",
    "    \n",
    "    # Create a colormap\n",
    "    cmap = plt.cm.get_cmap('Reds')\n",
    "    # Choose a shade of red\n",
    "    hr_shade = cmap(0.75)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('Blues')\n",
    "    # Choose a shade of red\n",
    "    lr_shade = cmap(0.75)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "\n",
    "    data_high_risk = data_df1\n",
    "    data_low_risk = data_df2\n",
    "\n",
    "    kmf_hr = KaplanMeierFitter()\n",
    "    kmf_hr.fit(data_high_risk['time'], event_observed=data_high_risk['event'], label='RT+ADT')\n",
    "    kmf_hr.plot_survival_function(ax=ax, color='#f8766d', lw=2, show_censors=True)\n",
    "\n",
    "    kmf_lr = KaplanMeierFitter()\n",
    "    kmf_lr.fit(data_low_risk['time'], event_observed=data_low_risk['event'], label='RT+ADT+CT')\n",
    "    kmf_lr.plot_survival_function(ax=ax, color='#03bfc4', lw=2, show_censors=True, )\n",
    "    \n",
    "    \n",
    "    print(\"Low risk median survival time: \",kmf_lr.median_survival_time_)\n",
    "    print(\"High risk median survival time: \",kmf_hr.median_survival_time_)\n",
    "    max_median_survival_time = max(kmf_hr.median_survival_time_ , kmf_lr.median_survival_time_)\n",
    "    if max_median_survival_time == np.inf:\n",
    "        plt.axhline(y=0.5, color='black', linestyle='--', lw=1)\n",
    "    else:\n",
    "        plt.plot([0, max_median_survival_time], [0.5, 0.5], color='black', linestyle='--', lw=1)\n",
    "    # Vertical lines up to y=0.5, using plot for precise control\n",
    "    plt.plot([kmf_hr.median_survival_time_, kmf_hr.median_survival_time_], [0, 0.5], color='black', linestyle='--', lw=1)\n",
    "    plt.plot([kmf_lr.median_survival_time_, kmf_lr.median_survival_time_], [0, 0.5], color='black', linestyle='--', lw=1)\n",
    "    ax.set_title(title_str, fontsize=26)\n",
    "\n",
    "    yticks = [np.round(x,1) for x in ax.get_yticks()]\n",
    "    ax.set_yticklabels(yticks, fontsize=20)\n",
    "    ax.set_xticklabels(ax.get_xticks().astype(int), fontsize=20)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (Years)', fontsize=28)\n",
    "    ax.set_ylabel('Overall Survival Probability', fontsize=28)\n",
    "    data_p, data_hr, data_ci_lower, data_ci_upper = data_stats\n",
    "    format_p = lambda p: f\"{p:.1e}\" if p < 0.001 else f\"{p:.4f}\"\n",
    "\n",
    "# Updated string formatting\n",
    "    data_stats_text = f'p: {format_p(data_p)}\\nHR: {data_hr:.2f} [95% CI: {data_ci_lower:.2f} - {data_ci_upper:.2f}]'\n",
    "    #data_stats_text = f'p: {data_p:.1e if data_p < 0.001 else data_p:.4f}\\nHR: {data_hr:.2f} [95% CI: {data_ci_lower:.2f} - {data_ci_upper:.2f}]'\n",
    "    ax.text(0.03, 0.1, data_stats_text, transform=ax.transAxes, fontsize=24, verticalalignment='bottom')\n",
    "\n",
    "    # Add the risk table at the bottom of the KM plot on ax[1] (the bottom subplot)\n",
    "    sns.despine()\n",
    "    add_at_risk_counts(kmf_hr, kmf_lr, ax=ax, fontsize=20)\n",
    "    ax.legend(fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(figure_save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_km_same_risk_group(no_chemo_favorable_risk, chemo_favorable_risk, doce_holdout_data_stats, 'APIC_low_both_legs_km.png', \"APIC-low RT+ADT vs RT+ADT+CT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_survival_benefit(data_df1, data_df2, time_points=[1,3, 5,7, 10]):\n",
    "    # Initialize Kaplan-Meier fitters for each group\n",
    "    kmf_hr = KaplanMeierFitter()  # High risk group\n",
    "    kmf_lr = KaplanMeierFitter()  # Low risk group\n",
    "\n",
    "    # Fit data for high risk group\n",
    "    kmf_hr.fit(data_df1['time'], event_observed=data_df1['event'])\n",
    "\n",
    "    # Fit data for low risk group\n",
    "    kmf_lr.fit(data_df2['time'], event_observed=data_df2['event'])\n",
    "\n",
    "    # Calculate survival probabilities at specified time points\n",
    "    survival_hr = kmf_hr.survival_function_.reindex(time_points, method='nearest')\n",
    "    survival_lr = kmf_lr.survival_function_.reindex(time_points, method='nearest')\n",
    "\n",
    "    # Calculate differences in survival probabilities and format them\n",
    "    survival_benefits = {}\n",
    "    for t in time_points:\n",
    "        prob_hr = kmf_hr.predict(t)\n",
    "        prob_lr = kmf_lr.predict(t)\n",
    "        survival_benefit = (prob_lr - prob_hr) * 100  # in percentage points\n",
    "        survival_benefits[t] = survival_benefit\n",
    "\n",
    "    return survival_benefits\n",
    "\n",
    "# Example usage:\n",
    "# Assuming data_df1 and data_df2 are your dataframes for the two risk groups\n",
    "benefits = calculate_survival_benefit(no_chemo_favorable_risk, chemo_favorable_risk)\n",
    "print(\"Survival Benefits at specified time points:\", benefits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_bad_risk = y_holdout_doce[y_holdout_doce['risk_group'] == 1]\n",
    "no_chemo_bad_risk = y_holdout[y_holdout['risk_group'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_bad_risk['chemo'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chemo_bad_risk['chemo'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_risk = pd.concat([chemo_bad_risk, no_chemo_bad_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_holdout_doce = bad_risk.drop(['patient_id', 'risk_group', 'risk_score'], axis=1)\n",
    "cph_holdout_doce = CoxPHFitter()\n",
    "cph_holdout_doce.fit(LL_holdout_doce, duration_col='time', event_col='event', show_progress=False)\n",
    "\n",
    "doce_holdout_results = cph_holdout_doce.summary\n",
    "doce_holdout_p = multivariate_logrank_test(bad_risk['time'], bad_risk['chemo'], bad_risk['event']).p_value # holdout_results['p'].values[0] # change group to chemo/nochemo\n",
    "doce_holdout_hr = doce_holdout_results['exp(coef)'].values[0]\n",
    "doce_holdout_ci_lower = doce_holdout_results['exp(coef) lower 95%'].values[0]\n",
    "doce_holdout_ci_upper = doce_holdout_results['exp(coef) upper 95%'].values[0]\n",
    "doce_holdout_log_likelihood = cph_holdout_doce.log_likelihood_\n",
    "model_metrics_doce['holdout_p_value'] = [doce_holdout_p]\n",
    "model_metrics_doce['holdout_hazard_ratio'] = [doce_holdout_hr]\n",
    "model_metrics_doce['holdout_hr_ci_lower'] = [doce_holdout_ci_lower]\n",
    "model_metrics_doce['holdout_hr_ci_upper'] = [doce_holdout_ci_upper]\n",
    "model_metrics_doce['holdout_log_likelihood'] = [doce_holdout_log_likelihood]\n",
    "model_metrics_doce['holdout_parameters'] = [cph_holdout_doce.params_.shape[0]]\n",
    "\n",
    "doce_holdout_data_stats = (doce_holdout_p, doce_holdout_hr, doce_holdout_ci_lower, doce_holdout_ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce_holdout_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_km_same_risk_group(no_chemo_bad_risk, chemo_bad_risk, doce_holdout_data_stats, 'APIC_high_both_legs_km.png', \"APIC-high RT+ADT vs RT+ADT+CT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = calculate_survival_benefit(no_chemo_bad_risk, chemo_bad_risk)\n",
    "print(\"Survival Benefits at specified time points:\", benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_holdout_doce.print_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
